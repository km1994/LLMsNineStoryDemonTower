# LLMsNineStoryDemonTower LLMsä¹å±‚å¦–å¡”
ã€LLMsä¹å±‚å¦–å¡”ã€‘åˆ†äº«ä¸€ä¸‹æ‰“æ€ª(ChatGLMã€Chinese-LLaMA-Alpacaã€MiniGPT-4ã€FastChatã€LLaMAã€gpt4allç­‰)å®æˆ˜ä¸ç»éªŒï¼Œ

![LLMsä¹å±‚å¦–å¡” è§†é¢‘ä»‹ç»](https://github.com/km1994/LLMsNineStoryDemonTower/blob/main/mp4/LLMsä¹å±‚å¦–å¡”æŒ‘æˆ˜èµ›.mp4)
> [LLMsä¹å±‚å¦–å¡” è§†é¢‘ä»‹ç» åœ°å€](https://github.com/km1994/LLMsNineStoryDemonTower/blob/main/mp4/LLMsä¹å±‚å¦–å¡”æŒ‘æˆ˜èµ›.mp4)

- [LLMsNineStoryDemonTower LLMsä¹å±‚å¦–å¡”](#llmsninestorydemontower-llmsä¹å±‚å¦–å¡”)
  - [ã€LLMs å…¥é—¨å®æˆ˜ç³»åˆ—ã€‘](#llms-å…¥é—¨å®æˆ˜ç³»åˆ—)
    - [ç¬¬ä¸€å±‚ ChatGLM-6B](#ç¬¬ä¸€å±‚-chatglm-6b)
      - [å†…å®¹å¤§çº²](#å†…å®¹å¤§çº²)
    - [ç¬¬äºŒå±‚ Stanford Alpaca 7B](#ç¬¬äºŒå±‚-stanford-alpaca-7b)
    - [ç¬¬ä¸‰å±‚ Chinese-LLaMA-Alpaca](#ç¬¬ä¸‰å±‚-chinese-llama-alpaca)
    - [ç¬¬å››å±‚ å°ç¾Šé©¼ Vicuna](#ç¬¬å››å±‚-å°ç¾Šé©¼-vicuna)
    - [ç¬¬äº”å±‚ MiniGPT-4](#ç¬¬äº”å±‚-minigpt-4)
    - [ç¬¬å…­å±‚ GPT4ALL](#ç¬¬å…­å±‚-gpt4all)
    - [ç¬¬ä¸ƒå±‚ AutoGPT](#ç¬¬ä¸ƒå±‚-autogpt)
    - [ç¬¬å…«å±‚ MOSS](#ç¬¬å…«å±‚-moss)
  - [å­¦ä¹ ç¾¤](#å­¦ä¹ ç¾¤)
  - [ä¼˜ç§€ç¬”è®°](#ä¼˜ç§€ç¬”è®°)
    - [ç¬¬ä¸€å±‚](#ç¬¬ä¸€å±‚)
    - [ä¼˜ç§€ç¬”è®°](#ä¼˜ç§€ç¬”è®°-1)
  - [å‚è€ƒ](#å‚è€ƒ)

## ã€LLMs å…¥é—¨å®æˆ˜ç³»åˆ—ã€‘

### ç¬¬ä¸€å±‚ ChatGLM-6B

#### å†…å®¹å¤§çº²

1. [ã€ChatGLM-6Bå…¥é—¨-ä¸€ã€‘æ¸…åå¤§å­¦å¼€æºä¸­æ–‡ç‰ˆChatGLM-6Bæ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](ChatGLM-6B/induction.md)
   - ä»‹ç»ï¼šChatGLM-6B ç¯å¢ƒé…ç½® å’Œ éƒ¨ç½²
   - github é¡¹ç›®ï¼šhttps://github.com/THUDM/ChatGLM-6B
   - huggingface Weightsï¼š
     - https://huggingface.co/THUDM/chatglm-6b
2. [ã€ChatGLM-6Bå…¥é—¨-äºŒã€‘æ¸…åå¤§å­¦å¼€æºä¸­æ–‡ç‰ˆChatGLM-6Bæ¨¡å‹å¾®è°ƒå®æˆ˜](ChatGLM-6B/ptuning.md)
   - ä»‹ç»ï¼šChatGLM-6B P-Tuning V2 å¾®è°ƒï¼šFine-tuning the prefix encoder of the model.
   - github é¡¹ç›®ï¼šhttps://github.com/THUDM/ChatGLM-6B
   - huggingface Weightsï¼š
     - https://huggingface.co/THUDM/chatglm-6b

3. [ã€ChatGLM-6Bå…¥é—¨-ä¸‰ã€‘ChatGLM ç‰¹å®šä»»åŠ¡å¾®è°ƒå®æˆ˜](ChatGLM-6B/ptuning_in_my_data.md)
   - ä»‹ç»ï¼šå¯¹äº ChatGLM-6B æ¨¡å‹åŸºäº [P-Tuning v2](https://github.com/THUDM/P-tuning-v2) çš„ç‰¹å®šä»»åŠ¡å¾®è°ƒå®éªŒï¼Œå¾®è°ƒç›®æ ‡ä¸ºè‡ªåŠ¨ç”Ÿæˆçš„æ•´æ•°/å°æ•°åŠ å‡ä¹˜é™¤è¿ç®—ã€‚
   - github é¡¹ç›®ï¼š
     - https://github.com/THUDM/ChatGLM-6B
     - https://github.com/yongzhuo/chatglm-maths
   - huggingface Weightsï¼š
     - https://huggingface.co/THUDM/chatglm-6b
   - è®­ç»ƒæ•°æ®é›†ï¼š
     - [BelleGroup/school_math_0.25M](https://huggingface.co/datasets/BelleGroup/school_math_0.25M) 
  
4. [ã€ChatGLM-6Bå…¥é—¨-å››ã€‘ChatGLM + LoRA è¿›è¡Œfinetune](ChatGLM-6B/LoRA_finetune.md)
   - ä»‹ç»ï¼šChatGLM-6B LoRA å¾®è°ƒï¼šFine-tuning the low-rank adapters of the model.
   - github é¡¹ç›®ï¼š
     - https://github.com/mymusise/ChatGLM-Tuning
   - huggingface Weightsï¼š
     - https://huggingface.co/THUDM/chatglm-6b
5. [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åä¸€ ã€‘åŸºäº ğŸ¤—PEFT çš„é«˜æ•ˆ ğŸ¤–ChatGLM-6B å¾®è°ƒ](https://articles.zsxq.com/id_7rz5jtfguuc5.html)
   - å¾®è°ƒæ–¹å¼ï¼š
     - ChatGLM-6B Freeze å¾®è°ƒï¼šFine-tuning the MLPs in the last n blocks of the model.
     - ChatGLM-6B P-Tuning V2 å¾®è°ƒï¼šFine-tuning the prefix encoder of the model.
     - ChatGLM-6B LoRA å¾®è°ƒï¼šFine-tuning the low-rank adapters of the model.
6. [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åäºŒ ã€‘åŸºäº æœ¬åœ°çŸ¥è¯†åº“ çš„é«˜æ•ˆ ğŸ¤–langchain-ChatGLM ](https://articles.zsxq.com/id_54vjwns5t6in.html)
   - ä»‹ç»ï¼šlangchain-ChatGLMæ˜¯ä¸€ä¸ªåŸºäºæœ¬åœ°çŸ¥è¯†çš„é—®ç­”æœºå™¨äººï¼Œä½¿ç”¨è€…å¯ä»¥è‡ªç”±é…ç½®æœ¬åœ°çŸ¥è¯†ï¼Œç”¨æˆ·é—®é¢˜çš„ç­”æ¡ˆä¹Ÿæ˜¯åŸºäºæœ¬åœ°çŸ¥è¯†ç”Ÿæˆçš„ã€‚
7. [ChatGLM-6B å°ç¼–å¡«å‘è®°](https://articles.zsxq.com/id_fw7vn0mhdsnq.html)
   - ä»‹ç»ï¼šChatGLM-6B åœ¨ éƒ¨ç½²å’Œå¾®è°ƒ è¿‡ç¨‹ä¸­ ä¼šé‡åˆ°å¾ˆå¤šå‘ï¼Œå°ç¼–æ‰å‘äº†å¾ˆå¤šæ¬¡ï¼Œä¸ºé˜²æ­¢ åäººå’Œå°ç¼–ä¸€æ ·ç»§ç»­æ‰å‘ï¼Œå°ç¼–ç´¢æ€§æŠŠé‡åˆ°çš„å‘éƒ½å¡«äº†ã€‚
8. [ã€LLMså­¦ä¹ ã€‘å…³äºå¤§æ¨¡å‹å®è·µçš„ä¸€äº›æ€»ç»“](https://articles.zsxq.com/id_il58nxrs9jxr.html)

### ç¬¬äºŒå±‚ Stanford Alpaca 7B 

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” äº” ã€‘Stanford Alpaca 7B æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](Stanford_Alpaca_7B/readme.md)
  - ä»‹ç»ï¼šæœ¬æ•™ç¨‹æä¾›äº†å¯¹LLaMAæ¨¡å‹è¿›è¡Œå¾®è°ƒçš„å»‰ä»·äº²æ°‘ LLMs å­¦ä¹ å’Œå¾®è°ƒ æ–¹å¼ï¼Œä¸»è¦ä»‹ç»å¯¹äº Stanford Alpaca 7B æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Š çš„ å¾®è°ƒå®éªŒï¼Œæ‰€ç”¨çš„æ•°æ®ä¸ºOpenAIæä¾›çš„GPTæ¨¡å‹APIç”Ÿæˆè´¨é‡è¾ƒé«˜çš„æŒ‡ä»¤æ•°æ®ï¼ˆä»…52kï¼‰ã€‚
  - github é¡¹ç›®ï¼š
    - https://github.com/tatsu-lab/stanford_alpaca
  - huggingface Weightsï¼š
    - https://huggingface.co/P01son/ChatLLaMA-zh-7B

### ç¬¬ä¸‰å±‚ Chinese-LLaMA-Alpaca 

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” å…­ ã€‘Chinese-LLaMA-Alpaca æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](Chinese-LLaMA-Alpaca/readme.md)
  - ä»‹ç»ï¼šæœ¬æ•™ç¨‹ä¸»è¦ä»‹ç»äº† Chinese-ChatLLaMA,æä¾›ä¸­æ–‡å¯¹è¯æ¨¡å‹ ChatLLama ã€ä¸­æ–‡åŸºç¡€æ¨¡å‹ LLaMA-zh åŠå…¶è®­ç»ƒæ•°æ®ã€‚ æ¨¡å‹åŸºäº TencentPretrain å¤šæ¨¡æ€é¢„è®­ç»ƒæ¡†æ¶æ„å»º
  - github é¡¹ç›®ï¼š
    - https://github.com/ydli-ai/Chinese-ChatLLaMA
  - huggingface Weightsï¼š
    - https://huggingface.co/decapoda-research/llama-7b-hf

### ç¬¬å››å±‚ å°ç¾Šé©¼ Vicuna

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” ä¸ƒ ã€‘å°ç¾Šé©¼ Vicunaæ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](Vicuna/readme.md)
  - ä»‹ç»ï¼šUCä¼¯å…‹åˆ©å­¦è€…è”æ‰‹CMUã€æ–¯å¦ç¦ç­‰ï¼Œå†æ¬¡æ¨å‡ºä¸€ä¸ªå…¨æ–°æ¨¡å‹70äº¿/130äº¿å‚æ•°çš„Vicunaï¼Œä¿—ç§°ã€Œå°ç¾Šé©¼ã€ï¼ˆéª†é©¬ï¼‰ã€‚å°ç¾Šé©¼å·ç§°èƒ½è¾¾åˆ°GPT-4çš„90%æ€§èƒ½
  - github é¡¹ç›®ï¼š
    - https://github.com/lm-sys/FastChat
  - huggingface Weightsï¼š
    - https://huggingface.co/lmsys/vicuna-7b-delta-v1.1
    - https://huggingface.co/decapoda-research/llama-7b-hf

### ç¬¬äº”å±‚ MiniGPT-4 

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” å…« ã€‘MiniGPT-4 æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](mingpt/readme.md)
  - ä»‹ç»ï¼š MiniGPT-4ï¼Œæ˜¯æ¥è‡ªé˜¿åœæœæ‹‰å›½ç‹ç§‘æŠ€å¤§å­¦çš„å‡ ä½åšå£«åšçš„ï¼Œå®ƒèƒ½æä¾›ç±»ä¼¼ GPT-4 çš„å›¾åƒç†è§£ä¸å¯¹è¯èƒ½åŠ›

### ç¬¬å…­å±‚ GPT4ALL

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” å…« ã€‘GPT4ALL æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_ff0w6czthq25.html)
  - ä»‹ç»ï¼šä¸€ä¸ª å¯ä»¥åœ¨è‡ªå·±ç¬”è®°æœ¬ä¸Šé¢è·‘èµ·æ¥çš„  Nomic AI çš„åŠ©æ‰‹å¼èŠå¤©æœºå™¨äººï¼Œæˆä¸ºè´«æ°‘å®¶å­©å­çš„ ç¦éŸ³ï¼

### ç¬¬ä¸ƒå±‚ AutoGPT

- [AutoGPT ä½¿ç”¨å’Œéƒ¨ç½²](https://articles.zsxq.com/id_pli0z9916126.html)
  - ä»‹ç»ï¼šAuto-GPTæ˜¯ä¸€ä¸ªåŸºäºChatGPTçš„å·¥å…·ï¼Œä»–èƒ½å¸®ä½ è‡ªåŠ¨å®Œæˆå„ç§ä»»åŠ¡ï¼Œæ¯”å¦‚å†™ä»£ç ã€å†™æŠ¥å‘Šã€åšè°ƒç ”ç­‰ç­‰ã€‚ä½¿ç”¨å®ƒæ—¶ï¼Œä½ åªéœ€è¦å‘Šè¯‰ä»–è¦æ‰®æ¼”çš„è§’è‰²å’Œè¦å®ç°çš„ç›®æ ‡ï¼Œç„¶åä»–å°±ä¼šåˆ©ç”¨ChatGPTå’Œè°·æ­Œæœç´¢ç­‰å·¥å…·ï¼Œä¸æ–­â€œæ€è€ƒâ€å¦‚ä½•æ¥è¿‘ç›®æ ‡å¹¶æ‰§è¡Œï¼Œä½ ç”šè‡³å¯ä»¥çœ‹åˆ°ä»–çš„æ€è€ƒè¿‡ç¨‹ã€‚

### ç¬¬å…«å±‚ MOSS

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åä¸‰ ã€‘MOSS æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_4vwpxod23zrc.html)
  - ä»‹ç»ï¼šMOSSæ˜¯ä¸€ä¸ªæ”¯æŒä¸­è‹±åŒè¯­å’Œå¤šç§æ’ä»¶çš„å¼€æºå¯¹è¯è¯­è¨€æ¨¡å‹ï¼Œmoss-moonç³»åˆ—æ¨¡å‹å…·æœ‰160äº¿å‚æ•°ï¼Œåœ¨FP16ç²¾åº¦ä¸‹å¯åœ¨å•å¼ A100/A800æˆ–ä¸¤å¼ 3090æ˜¾å¡è¿è¡Œï¼Œåœ¨INT4/8ç²¾åº¦ä¸‹å¯åœ¨å•å¼ 3090æ˜¾å¡è¿è¡Œã€‚MOSSåŸºåº§è¯­è¨€æ¨¡å‹åœ¨çº¦ä¸ƒåƒäº¿ä¸­è‹±æ–‡ä»¥åŠä»£ç å•è¯ä¸Šé¢„è®­ç»ƒå¾—åˆ°ï¼Œåç»­ç»è¿‡å¯¹è¯æŒ‡ä»¤å¾®è°ƒã€æ’ä»¶å¢å¼ºå­¦ä¹ å’Œäººç±»åå¥½è®­ç»ƒå…·å¤‡å¤šè½®å¯¹è¯èƒ½åŠ›åŠä½¿ç”¨å¤šç§æ’ä»¶çš„èƒ½åŠ›ã€‚
  - å±€é™æ€§ï¼šç”±äºæ¨¡å‹å‚æ•°é‡è¾ƒå°å’Œè‡ªå›å½’ç”ŸæˆèŒƒå¼ï¼ŒMOSSä»ç„¶å¯èƒ½ç”ŸæˆåŒ…å«äº‹å®æ€§é”™è¯¯çš„è¯¯å¯¼æ€§å›å¤æˆ–åŒ…å«åè§/æ­§è§†çš„æœ‰å®³å†…å®¹ï¼Œè¯·è°¨æ…é‰´åˆ«å’Œä½¿ç”¨MOSSç”Ÿæˆçš„å†…å®¹ï¼Œè¯·å‹¿å°†MOSSç”Ÿæˆçš„æœ‰å®³å†…å®¹ä¼ æ’­è‡³äº’è”ç½‘ã€‚è‹¥äº§ç”Ÿä¸è‰¯åæœï¼Œç”±ä¼ æ’­è€…è‡ªè´Ÿã€‚

## å­¦ä¹ ç¾¤

![[å­¦ä¹ ç¾¤äºŒç»´ç ](img/20230516092740.jpg)](img/20230516092740.jpg)

## ä¼˜ç§€ç¬”è®°

### ç¬¬ä¸€å±‚

### ä¼˜ç§€ç¬”è®°

1. [æ¨å¤•](https://mp.weixin.qq.com/s/4QNgF6nAUo8imSaIB_OWmg)
2. [å¥”è…¾](https://articles.zsxq.com/id_k2qzsps7zw21.html)
3. [é€¸å°˜](https://articles.zsxq.com/id_zzfqt88sw4rl.html)
4. [æ­¤æ–¹ä¸€æ³‰](https://t.zsxq.com/0dEp8PDcW)
5. [vezel](http://t.csdn.cn/hWn9D)
6. [å¾ç”Ÿ](https://zhuanlan.zhihu.com/p/627358709)
7. [å¤šç‚¹å¾®ç¬‘](https://articles.zsxq.com/id_velwvtmfhrwz.html)
8. [å°å›º](https://zhuanlan.zhihu.com/p/627333187)
9. [åœŸç‹¼](https://zhuanlan.zhihu.com/p/627358709)
10. [0](https://github.com/Wesley12138/LLM)
11. [Welch](https://t.zsxq.com/0dJhaaGRW)
12. [ä¹çŒ«](https://articles.zsxq.com/id_7g0g65fbsluo.html)


## å‚è€ƒ

1. [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)
2. [Stanford Alpaca 7B](https://github.com/tatsu-lab/stanford_alpaca)
3. [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
4. [Vicuna](https://github.com/lm-sys/FastChat)
5. [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)
6. [GPT4ALL](https://github.com/nomic-ai/gpt4all)
7. [Auto-GPT](hhttps://github.com/Significant-Gravitas/Auto-GPT)
8. [MOSS](https://github.com/OpenLMLab/MOSS/tree/main)
