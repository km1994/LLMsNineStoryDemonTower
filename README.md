# LLMsNineStoryDemonTower LLMsä¹å±‚å¦–å¡”
ã€LLMsä¹å±‚å¦–å¡”ã€‘åˆ†äº«ä¸€ä¸‹æ‰“æ€ª(ChatGLMã€Chinese-LLaMA-Alpacaã€MiniGPT-4ã€FastChatã€LLaMAã€gpt4allç­‰)å®æˆ˜ä¸ç»éªŒï¼Œ

![LLMsä¹å±‚å¦–å¡” è§†é¢‘ä»‹ç»](https://github.com/km1994/LLMsNineStoryDemonTower/blob/main/mp4/LLMsä¹å±‚å¦–å¡”æŒ‘æˆ˜èµ›.mp4)
> [LLMsä¹å±‚å¦–å¡” è§†é¢‘ä»‹ç» åœ°å€](https://github.com/km1994/LLMsNineStoryDemonTower/blob/main/mp4/LLMsä¹å±‚å¦–å¡”æŒ‘æˆ˜èµ›.mp4)

- [LLMsNineStoryDemonTower LLMsä¹å±‚å¦–å¡”](#llmsninestorydemontower-llmsä¹å±‚å¦–å¡”)
  - [ã€LLMs å…¥é—¨å®æˆ˜ç³»åˆ—ã€‘](#llms-å…¥é—¨å®æˆ˜ç³»åˆ—)
    - [ç¬¬ä¸€å±‚ LLMs to Natural Language Processing (NLP)](#ç¬¬ä¸€å±‚-llms-to-natural-language-processing-nlp)
      - [ç¬¬ä¸€é‡ ChatGLM-6B](#ç¬¬ä¸€é‡-chatglm-6b)
      - [ç¬¬äºŒé‡ Stanford Alpaca 7B](#ç¬¬äºŒé‡-stanford-alpaca-7b)
      - [ç¬¬ä¸‰é‡ Chinese-LLaMA-Alpaca](#ç¬¬ä¸‰é‡-chinese-llama-alpaca)
      - [ç¬¬å››é‡ å°ç¾Šé©¼ Vicuna](#ç¬¬å››é‡-å°ç¾Šé©¼-vicuna)
      - [ç¬¬äº”é‡ GPT4ALL](#ç¬¬äº”é‡-gpt4all)
      - [ç¬¬å…­é‡ MOSS](#ç¬¬å…­é‡-moss)
      - [ç¬¬ä¸ƒé‡ BLOOM](#ç¬¬ä¸ƒé‡-bloom)
      - [ç¬¬å…«é‡ BELLE](#ç¬¬å…«é‡-belle)
      - [ç¬¬ä¹é‡ ChatRWKV](#ç¬¬ä¹é‡-chatrwkv)
    - [ç¬¬äºŒå±‚ LLMs to Intelligent Retrieval (IR)](#ç¬¬äºŒå±‚-llms-to-intelligent-retrieval-ir)
      - [ç¬¬ä¸€é‡ ChatGLM-6B](#ç¬¬ä¸€é‡-chatglm-6b-1)
    - [ç¬¬ä¸‰å±‚ LLMs to Visual Question Answering (VQA)](#ç¬¬ä¸‰å±‚-llms-to-visual-question-answering-vqa)
      - [ç¬¬ä¸€é‡ MiniGPT-4](#ç¬¬ä¸€é‡-minigpt-4)
      - [ç¬¬äºŒé‡ VisualGLM-6B](#ç¬¬äºŒé‡-visualglm-6b)
    - [ç¬¬å››å±‚ LLMs to Automatic Speech Recognition (ASR)](#ç¬¬å››å±‚-llms-to-automatic-speech-recognition-asr)
      - [ç¬¬ä¸€é‡ Massively Multilingual Speech (MMSï¼Œå¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³)](#ç¬¬ä¸€é‡-massively-multilingual-speech-mmså¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³)
    - [ç¬¬äº”å±‚ LLMs to Text To Speech (TTS)](#ç¬¬äº”å±‚-llms-to-text-to-speech-tts)
      - [ç¬¬ä¸€é‡ Massively Multilingual Speech (MMSï¼Œå¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³)](#ç¬¬ä¸€é‡-massively-multilingual-speech-mmså¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³-1)
    - [ç¬¬å…­å±‚ LLMs to Artifact](#ç¬¬å…­å±‚-llms-to-artifact)
      - [ç¬¬ä¸€é‡ AutoGPT](#ç¬¬ä¸€é‡-autogpt)
    - [ç¬¬ä¸ƒå±‚ LLMs to Parameter Efficient Fine-Tuning (PEFT)](#ç¬¬ä¸ƒå±‚-llms-to-parameter-efficient-fine-tuning-peft)
      - [ç¬¬ä¸€é‡ LLMTune](#ç¬¬ä¸€é‡-llmtune)
      - [ç¬¬äºŒé‡ Guanaco](#ç¬¬äºŒé‡-guanaco)
    - [ç¬¬å…«å±‚ LLMs to Vertical Field (VF)](#ç¬¬å…«å±‚-llms-to-vertical-field-vf)
      - [ç¬¬ä¸€é‡ èšå®ç›†(Cornucopia)](#ç¬¬ä¸€é‡-èšå®ç›†cornucopia)
      - [ç¬¬ä¹å±‚ LLMs to Trick](#ç¬¬ä¹å±‚-llms-to-trick)
  - [å­¦ä¹ ç¾¤](#å­¦ä¹ ç¾¤)
  - [ä¼˜ç§€ç¬”è®°](#ä¼˜ç§€ç¬”è®°)
    - [ç¬¬ä¸€å±‚](#ç¬¬ä¸€å±‚)
    - [ä¼˜ç§€ç¬”è®°](#ä¼˜ç§€ç¬”è®°-1)
  - [å‚è€ƒ](#å‚è€ƒ)

## ã€LLMs å…¥é—¨å®æˆ˜ç³»åˆ—ã€‘

### ç¬¬ä¸€å±‚ LLMs to Natural Language Processing (NLP)

#### ç¬¬ä¸€é‡ ChatGLM-6B

1. [ã€ChatGLM-6Bå…¥é—¨-ä¸€ã€‘æ¸…åå¤§å­¦å¼€æºä¸­æ–‡ç‰ˆChatGLM-6Bæ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](ChatGLM-6B/induction.md)
   1. ä»‹ç»ï¼šChatGLM-6B ç¯å¢ƒé…ç½® å’Œ éƒ¨ç½²
2. [ã€ChatGLM-6Bå…¥é—¨-äºŒã€‘æ¸…åå¤§å­¦å¼€æºä¸­æ–‡ç‰ˆChatGLM-6Bæ¨¡å‹å¾®è°ƒå®æˆ˜](ChatGLM-6B/ptuning.md)
   1. ChatGLM-6B P-Tuning V2 å¾®è°ƒï¼šFine-tuning the prefix encoder of the model.
3. [ã€ChatGLM-6Bå…¥é—¨-ä¸‰ã€‘ChatGLM ç‰¹å®šä»»åŠ¡å¾®è°ƒå®æˆ˜](https://articles.zsxq.com/id_3b42ukjdkwpt.html)
4. [ã€ChatGLM-6Bå…¥é—¨-å››ã€‘ChatGLM + LoRA è¿›è¡Œfinetune](https://articles.zsxq.com/id_e2389qm0w0sx.html)
   1. ä»‹ç»ï¼šChatGLM-6B LoRA å¾®è°ƒï¼šFine-tuning the low-rank adapters of the model.
5. [ChatGLM-6B å°ç¼–å¡«å‘è®°](https://articles.zsxq.com/id_fw7vn0mhdsnq.html)
   1. ä»‹ç»ï¼šChatGLM-6B åœ¨ éƒ¨ç½²å’Œå¾®è°ƒ è¿‡ç¨‹ä¸­ ä¼šé‡åˆ°å¾ˆå¤šå‘ï¼Œå°ç¼–æ‰å‘äº†å¾ˆå¤šæ¬¡ï¼Œä¸ºé˜²æ­¢ åäººå’Œå°ç¼–ä¸€æ ·ç»§ç»­æ‰å‘ï¼Œå°ç¼–ç´¢æ€§æŠŠé‡åˆ°çš„å‘éƒ½å¡«äº†ã€‚
6. [ã€LLMså­¦ä¹ ã€‘å…³äºå¤§æ¨¡å‹å®è·µçš„ä¸€äº›æ€»ç»“](https://articles.zsxq.com/id_il58nxrs9jxr.html)
7. [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åä¸€ ã€‘åŸºäº ğŸ¤—PEFT çš„é«˜æ•ˆ ğŸ¤–ChatGLM-6B å¾®è°ƒ](https://articles.zsxq.com/id_7rz5jtfguuc5.html)
   1. å¾®è°ƒæ–¹å¼ï¼š
      1. ChatGLM-6B Freeze å¾®è°ƒï¼šFine-tuning the MLPs in the last n blocks of the model.
      2. ChatGLM-6B P-Tuning V2 å¾®è°ƒï¼šFine-tuning the prefix encoder of the model.
      3. ChatGLM-6B LoRA å¾®è°ƒï¼šFine-tuning the low-rank adapters of the model.

#### ç¬¬äºŒé‡ Stanford Alpaca 7B 

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” äº” ã€‘Stanford Alpaca 7B æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_xnt3fvp2wxz0.html)
  - ä»‹ç»ï¼šæœ¬æ•™ç¨‹æä¾›äº†å¯¹LLaMAæ¨¡å‹è¿›è¡Œå¾®è°ƒçš„å»‰ä»·äº²æ°‘ LLMs å­¦ä¹ å’Œå¾®è°ƒ æ–¹å¼ï¼Œä¸»è¦ä»‹ç»å¯¹äº Stanford Alpaca 7B æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Š çš„ å¾®è°ƒå®éªŒï¼Œæ‰€ç”¨çš„æ•°æ®ä¸ºOpenAIæä¾›çš„GPTæ¨¡å‹APIç”Ÿæˆè´¨é‡è¾ƒé«˜çš„æŒ‡ä»¤æ•°æ®ï¼ˆä»…52kï¼‰ã€‚

#### ç¬¬ä¸‰é‡ Chinese-LLaMA-Alpaca 

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” å…­ ã€‘Chinese-LLaMA-Alpaca æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_dqvusswrdg6c.html)
  - ä»‹ç»ï¼šæœ¬æ•™ç¨‹ä¸»è¦ä»‹ç»äº† Chinese-ChatLLaMA,æä¾›ä¸­æ–‡å¯¹è¯æ¨¡å‹ ChatLLama ã€ä¸­æ–‡åŸºç¡€æ¨¡å‹ LLaMA-zh åŠå…¶è®­ç»ƒæ•°æ®ã€‚ æ¨¡å‹åŸºäº TencentPretrain å¤šæ¨¡æ€é¢„è®­ç»ƒæ¡†æ¶æ„å»º

#### ç¬¬å››é‡ å°ç¾Šé©¼ Vicuna

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” ä¸ƒ ã€‘å°ç¾Šé©¼ Vicunaæ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_q9mx24q9fdab.html)
  - ä»‹ç»ï¼šUCä¼¯å…‹åˆ©å­¦è€…è”æ‰‹CMUã€æ–¯å¦ç¦ç­‰ï¼Œå†æ¬¡æ¨å‡ºä¸€ä¸ªå…¨æ–°æ¨¡å‹70äº¿/130äº¿å‚æ•°çš„Vicunaï¼Œä¿—ç§°ã€Œå°ç¾Šé©¼ã€ï¼ˆéª†é©¬ï¼‰ã€‚å°ç¾Šé©¼å·ç§°èƒ½è¾¾åˆ°GPT-4çš„90%æ€§èƒ½

#### ç¬¬äº”é‡ GPT4ALL

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” å…« ã€‘GPT4ALL æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_ff0w6czthq25.html)
  - ä»‹ç»ï¼šä¸€ä¸ª å¯ä»¥åœ¨è‡ªå·±ç¬”è®°æœ¬ä¸Šé¢è·‘èµ·æ¥çš„  Nomic AI çš„åŠ©æ‰‹å¼èŠå¤©æœºå™¨äººï¼Œæˆä¸ºè´«æ°‘å®¶å­©å­çš„ ç¦éŸ³ï¼

#### ç¬¬å…­é‡ MOSS

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åä¸‰ ã€‘MOSS æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_4vwpxod23zrc.html)
  - ä»‹ç»ï¼šMOSSæ˜¯ä¸€ä¸ªæ”¯æŒä¸­è‹±åŒè¯­å’Œå¤šç§æ’ä»¶çš„å¼€æºå¯¹è¯è¯­è¨€æ¨¡å‹ï¼Œmoss-moonç³»åˆ—æ¨¡å‹å…·æœ‰160äº¿å‚æ•°ï¼Œåœ¨FP16ç²¾åº¦ä¸‹å¯åœ¨å•å¼ A100/A800æˆ–ä¸¤å¼ 3090æ˜¾å¡è¿è¡Œï¼Œåœ¨INT4/8ç²¾åº¦ä¸‹å¯åœ¨å•å¼ 3090æ˜¾å¡è¿è¡Œã€‚MOSSåŸºåº§è¯­è¨€æ¨¡å‹åœ¨çº¦ä¸ƒåƒäº¿ä¸­è‹±æ–‡ä»¥åŠä»£ç å•è¯ä¸Šé¢„è®­ç»ƒå¾—åˆ°ï¼Œåç»­ç»è¿‡å¯¹è¯æŒ‡ä»¤å¾®è°ƒã€æ’ä»¶å¢å¼ºå­¦ä¹ å’Œäººç±»åå¥½è®­ç»ƒå…·å¤‡å¤šè½®å¯¹è¯èƒ½åŠ›åŠä½¿ç”¨å¤šç§æ’ä»¶çš„èƒ½åŠ›ã€‚
  - å±€é™æ€§ï¼šç”±äºæ¨¡å‹å‚æ•°é‡è¾ƒå°å’Œè‡ªå›å½’ç”ŸæˆèŒƒå¼ï¼ŒMOSSä»ç„¶å¯èƒ½ç”ŸæˆåŒ…å«äº‹å®æ€§é”™è¯¯çš„è¯¯å¯¼æ€§å›å¤æˆ–åŒ…å«åè§/æ­§è§†çš„æœ‰å®³å†…å®¹ï¼Œè¯·è°¨æ…é‰´åˆ«å’Œä½¿ç”¨MOSSç”Ÿæˆçš„å†…å®¹ï¼Œè¯·å‹¿å°†MOSSç”Ÿæˆçš„æœ‰å®³å†…å®¹ä¼ æ’­è‡³äº’è”ç½‘ã€‚è‹¥äº§ç”Ÿä¸è‰¯åæœï¼Œç”±ä¼ æ’­è€…è‡ªè´Ÿã€‚

#### ç¬¬ä¸ƒé‡ BLOOM

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åå›› ã€‘ BLOOM æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_wd97899pkjqj.html)
  - ä»‹ç»ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²è¢«è¯æ˜èƒ½å¤Ÿæ ¹æ®ä¸€äº›æ¼”ç¤ºæˆ–è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ‰§è¡Œæ–°çš„ä»»åŠ¡ã€‚è™½ç„¶è¿™äº›èƒ½åŠ›å·²ç»å¯¼è‡´äº†å¹¿æ³›çš„é‡‡ç”¨ï¼Œä½†å¤§å¤šæ•°LLMæ˜¯ç”±èµ„æºä¸°å¯Œçš„ç»„ç»‡å¼€å‘çš„ï¼Œè€Œä¸”ç»å¸¸ä¸å¯¹å…¬ä¼—å¼€æ”¾ã€‚ä½œä¸ºä½¿è¿™ä¸€å¼ºå¤§æŠ€æœ¯æ°‘ä¸»åŒ–çš„ä¸€æ­¥ï¼Œæˆ‘ä»¬æå‡ºäº†BLOOMï¼Œä¸€ä¸ª176Bå‚æ•°çš„å¼€æ”¾æ€§è¯­è¨€æ¨¡å‹ï¼Œå®ƒçš„è®¾è®¡å’Œå»ºç«‹è¦æ„Ÿè°¢æ•°ç™¾åç ”ç©¶äººå‘˜çš„åˆä½œã€‚BLOOMæ˜¯ä¸€ä¸ªä»…æœ‰è§£ç å™¨çš„Transformerè¯­è¨€æ¨¡å‹ï¼Œå®ƒæ˜¯åœ¨ROOTSè¯­æ–™åº“ä¸Šè®­ç»ƒå‡ºæ¥çš„ï¼Œè¯¥æ•°æ®é›†åŒ…æ‹¬46ç§è‡ªç„¶è¯­è¨€å’Œ13ç§ç¼–ç¨‹è¯­è¨€ï¼ˆå…±59ç§ï¼‰çš„æ•°ç™¾ä¸ªæ¥æºã€‚æˆ‘ä»¬å‘ç°ï¼ŒBLOOMåœ¨å„ç§åŸºå‡†ä¸Šå–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œåœ¨ç»å†äº†å¤šä»»åŠ¡æç¤ºçš„å¾®è°ƒåï¼Œå…¶ç»“æœæ›´åŠ å¼ºå¤§ã€‚
  - æ¨¡å‹åœ°å€ï¼šhttps://huggingface.co/bigscience/bloomz

#### ç¬¬å…«é‡ BELLE

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åäº” ã€‘ BELLE æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_gxebzsadfpr2.html)
  - ä»‹ç»ï¼šç›¸æ¯”å¦‚ä½•åšå¥½å¤§è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒï¼ŒBELLEæ›´å…³æ³¨å¦‚ä½•åœ¨å¼€æºé¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œå¸®åŠ©æ¯ä¸€ä¸ªäººéƒ½èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ªå±äºè‡ªå·±çš„ã€æ•ˆæœå°½å¯èƒ½å¥½çš„å…·æœ‰æŒ‡ä»¤è¡¨ç°èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹ï¼Œé™ä½å¤§è¯­è¨€æ¨¡å‹ã€ç‰¹åˆ«æ˜¯ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹çš„ç ”ç©¶å’Œåº”ç”¨é—¨æ§›ã€‚ä¸ºæ­¤ï¼ŒBELLEé¡¹ç›®ä¼šæŒç»­å¼€æ”¾æŒ‡ä»¤è®­ç»ƒæ•°æ®ã€ç›¸å…³æ¨¡å‹ã€è®­ç»ƒä»£ç ã€åº”ç”¨åœºæ™¯ç­‰ï¼Œä¹Ÿä¼šæŒç»­è¯„ä¼°ä¸åŒè®­ç»ƒæ•°æ®ã€è®­ç»ƒç®—æ³•ç­‰å¯¹æ¨¡å‹è¡¨ç°çš„å½±å“ã€‚BELLEé’ˆå¯¹ä¸­æ–‡åšäº†ä¼˜åŒ–ï¼Œæ¨¡å‹è°ƒä¼˜ä»…ä½¿ç”¨ç”±ChatGPTç”Ÿäº§çš„æ•°æ®ï¼ˆä¸åŒ…å«ä»»ä½•å…¶ä»–æ•°æ®ï¼‰ã€‚
  - github åœ°å€: https://github.com/LianjiaTech/BELLE

#### ç¬¬ä¹é‡ ChatRWKV

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åå…« ã€‘ ChatRWKV æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜]()
  - ç›®å‰ RWKV æœ‰å¤§é‡æ¨¡å‹ï¼Œå¯¹åº”å„ç§åœºæ™¯ï¼Œå„ç§è¯­è¨€ï¼Œè¯·é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š
    - Raven æ¨¡å‹ï¼šé€‚åˆç›´æ¥èŠå¤©ï¼Œé€‚åˆ +i æŒ‡ä»¤ã€‚æœ‰å¾ˆå¤šç§è¯­è¨€çš„ç‰ˆæœ¬ï¼Œçœ‹æ¸…æ¥šç”¨å“ªä¸ªã€‚é€‚åˆèŠå¤©ã€å®Œæˆä»»åŠ¡ã€å†™ä»£ç ã€‚å¯ä»¥ä½œä¸ºä»»åŠ¡å»å†™æ–‡ç¨¿ã€å¤§çº²ã€æ•…äº‹ã€è¯—æ­Œç­‰ç­‰ï¼Œä½†æ–‡ç¬”ä¸å¦‚ testNovel ç³»åˆ—æ¨¡å‹ã€‚
    - Novel-ChnEng æ¨¡å‹ï¼šä¸­è‹±æ–‡å°è¯´æ¨¡å‹ï¼Œå¯ä»¥ç”¨ +gen ç”Ÿæˆä¸–ç•Œè®¾å®šï¼ˆå¦‚æœä¼šå†™ promptï¼Œå¯ä»¥æ§åˆ¶ä¸‹æ–‡å‰§æƒ…å’Œäººç‰©ï¼‰ï¼Œå¯ä»¥å†™ç§‘å¹»å¥‡å¹»ã€‚ä¸é€‚åˆèŠå¤©ï¼Œä¸é€‚åˆ +i æŒ‡ä»¤ã€‚
    - Novel-Chn æ¨¡å‹ï¼šçº¯ä¸­æ–‡ç½‘æ–‡æ¨¡å‹ï¼Œåªèƒ½ç”¨ +gen ç»­å†™ç½‘æ–‡ï¼ˆä¸èƒ½ç”Ÿæˆä¸–ç•Œè®¾å®šç­‰ç­‰ï¼‰ï¼Œä½†æ˜¯å†™ç½‘æ–‡å†™å¾—æ›´å¥½ï¼ˆä¹Ÿæ›´å°ç™½æ–‡ï¼Œé€‚åˆå†™ç”·é¢‘å¥³é¢‘ï¼‰ã€‚ä¸é€‚åˆèŠå¤©ï¼Œä¸é€‚åˆ +i æŒ‡ä»¤ã€‚
    - Novel-ChnEng-ChnPro æ¨¡å‹ï¼šå°† Novel-ChnEng åœ¨é«˜è´¨é‡ä½œå“å¾®è°ƒï¼ˆåè‘—ï¼Œç§‘å¹»ï¼Œå¥‡å¹»ï¼Œå¤å…¸ï¼Œç¿»è¯‘ï¼Œç­‰ç­‰ï¼‰ã€‚
  - github: https://github.com/BlinkDL/ChatRWKV
  -  æ¨¡å‹æ–‡ä»¶ï¼šhttps://huggingface.co/BlinkDL

### ç¬¬äºŒå±‚ LLMs to Intelligent Retrieval (IR)

#### ç¬¬ä¸€é‡ ChatGLM-6B

1. [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åäºŒ ã€‘åŸºäº æœ¬åœ°çŸ¥è¯†åº“ çš„é«˜æ•ˆ ğŸ¤–langchain-ChatGLM ](https://articles.zsxq.com/id_54vjwns5t6in.html)
   1. ä»‹ç»ï¼šlangchain-ChatGLMæ˜¯ä¸€ä¸ªåŸºäºæœ¬åœ°çŸ¥è¯†çš„é—®ç­”æœºå™¨äººï¼Œä½¿ç”¨è€…å¯ä»¥è‡ªç”±é…ç½®æœ¬åœ°çŸ¥è¯†ï¼Œç”¨æˆ·é—®é¢˜çš„ç­”æ¡ˆä¹Ÿæ˜¯åŸºäºæœ¬åœ°çŸ¥è¯†ç”Ÿæˆçš„ã€‚

### ç¬¬ä¸‰å±‚ LLMs to Visual Question Answering (VQA)

#### ç¬¬ä¸€é‡ MiniGPT-4 

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” å…« ã€‘MiniGPT-4 æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_ff0w6czthq25.html)
  - ä»‹ç»ï¼š MiniGPT-4ï¼Œæ˜¯æ¥è‡ªé˜¿åœæœæ‹‰å›½ç‹ç§‘æŠ€å¤§å­¦çš„å‡ ä½åšå£«åšçš„ï¼Œå®ƒèƒ½æä¾›ç±»ä¼¼ GPT-4 çš„å›¾åƒç†è§£ä¸å¯¹è¯èƒ½åŠ›

#### ç¬¬äºŒé‡ VisualGLM-6B

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åä¸ƒ ã€‘ VisualGLM-6B æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_4pzgwnwl2zjc.html)
  - åŠ¨æœºï¼šOpenAI çš„GPT-4æ ·ä¾‹ä¸­å±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œä½†æ˜¯èƒ½ç†è§£å›¾åƒçš„ä¸­æ–‡å¼€æºå¯¹è¯æ¨¡å‹ä»æ˜¯ç©ºç™½ã€‚
  - ä»‹ç»ï¼šVisualGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ï¼Œæ”¯æŒå›¾åƒã€ä¸­æ–‡å’Œè‹±æ–‡çš„å¤šæ¨¡æ€å¯¹è¯è¯­è¨€æ¨¡å‹ï¼Œè¯­è¨€æ¨¡å‹åŸºäº ChatGLM-6Bï¼Œå…·æœ‰ 62 äº¿å‚æ•°ï¼›å›¾åƒéƒ¨åˆ†é€šè¿‡è®­ç»ƒ BLIP2-Qformer æ„å»ºèµ·è§†è§‰æ¨¡å‹ä¸è¯­è¨€æ¨¡å‹çš„æ¡¥æ¢ï¼Œæ•´ä½“æ¨¡å‹å…± 78 äº¿å‚æ•°ã€‚

VisualGLM-6B ä¾é æ¥è‡ªäº CogView æ•°æ®é›†çš„30Mé«˜è´¨é‡ä¸­æ–‡å›¾æ–‡å¯¹ï¼Œä¸ 300M ç»è¿‡ç­›é€‰çš„è‹±æ–‡å›¾æ–‡å¯¹è¿›è¡Œé¢„è®­ç»ƒï¼Œä¸­è‹±æ–‡æƒé‡ç›¸åŒã€‚è¯¥è®­ç»ƒæ–¹å¼è¾ƒå¥½åœ°å°†è§†è§‰ä¿¡æ¯å¯¹é½åˆ° ChatGLM çš„è¯­ä¹‰ç©ºé—´ï¼›ä¹‹åçš„å¾®è°ƒé˜¶æ®µï¼Œæ¨¡å‹åœ¨é•¿è§†è§‰é—®ç­”æ•°æ®ä¸Šè®­ç»ƒï¼Œä»¥ç”Ÿæˆç¬¦åˆäººç±»åå¥½çš„ç­”æ¡ˆã€‚
  - github åœ°å€:https://github.com/THUDM/VisualGLM-6B

### ç¬¬å››å±‚ LLMs to Automatic Speech Recognition (ASR)

#### ç¬¬ä¸€é‡ Massively Multilingual Speech (MMSï¼Œå¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³)

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” äºŒå ã€‘ Massively Multilingual Speech (MMSï¼Œå¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³) æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://github.com/km1994/LLMsNineStoryDemonTower/tree/main/speech_MMS_21)
  - è®ºæ–‡ï¼š[Scaling Speech Technology to 1,000+ Languages](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/)
  - ä»£ç ï¼š[fairseq/tree/main/examples/mms](https://github.com/facebookresearch/fairseq/tree/main/examples/mms)
  - å…¬å‘Šï¼šhttps://ai.facebook.com/blog/multilingual-model-speech-recognition/
  - ä»‹ç»ï¼šMeta åœ¨ GitHub ä¸Šå†æ¬¡å¼€æºäº†ä¸€æ¬¾å…¨æ–°çš„ AI è¯­è¨€æ¨¡å‹â€”â€”Massively Multilingual Speech (MMSï¼Œå¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³)ï¼Œå®ƒä¸ ChatGPT æœ‰ç€å¾ˆå¤§çš„ä¸åŒï¼Œè¿™æ¬¾æ–°çš„è¯­è¨€æ¨¡å‹å¯ä»¥è¯†åˆ« 4000 å¤šç§å£å¤´è¯­è¨€å¹¶ç”Ÿæˆ 1100 å¤šç§è¯­éŸ³ï¼ˆæ–‡æœ¬åˆ°è¯­éŸ³ï¼‰ã€‚

### ç¬¬äº”å±‚ LLMs to Text To Speech (TTS)

#### ç¬¬ä¸€é‡ Massively Multilingual Speech (MMSï¼Œå¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³)

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” äºŒå ã€‘ Massively Multilingual Speech (MMSï¼Œå¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³) æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://github.com/km1994/LLMsNineStoryDemonTower/tree/main/speech_MMS_21)
  - è®ºæ–‡ï¼š[Scaling Speech Technology to 1,000+ Languages](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/)
  - ä»£ç ï¼š[fairseq/tree/main/examples/mms](https://github.com/facebookresearch/fairseq/tree/main/examples/mms)
  - å…¬å‘Šï¼šhttps://ai.facebook.com/blog/multilingual-model-speech-recognition/
  - ä»‹ç»ï¼šMeta åœ¨ GitHub ä¸Šå†æ¬¡å¼€æºäº†ä¸€æ¬¾å…¨æ–°çš„ AI è¯­è¨€æ¨¡å‹â€”â€”Massively Multilingual Speech (MMSï¼Œå¤§è§„æ¨¡å¤šè¯­ç§è¯­éŸ³)ï¼Œå®ƒä¸ ChatGPT æœ‰ç€å¾ˆå¤§çš„ä¸åŒï¼Œè¿™æ¬¾æ–°çš„è¯­è¨€æ¨¡å‹å¯ä»¥è¯†åˆ« 4000 å¤šç§å£å¤´è¯­è¨€å¹¶ç”Ÿæˆ 1100 å¤šç§è¯­éŸ³ï¼ˆæ–‡æœ¬åˆ°è¯­éŸ³ï¼‰ã€‚

### ç¬¬å…­å±‚ LLMs to Artifact

#### ç¬¬ä¸€é‡ AutoGPT

- [AutoGPT ä½¿ç”¨å’Œéƒ¨ç½²](https://articles.zsxq.com/id_pli0z9916126.html)
  - ä»‹ç»ï¼šAuto-GPTæ˜¯ä¸€ä¸ªåŸºäºChatGPTçš„å·¥å…·ï¼Œä»–èƒ½å¸®ä½ è‡ªåŠ¨å®Œæˆå„ç§ä»»åŠ¡ï¼Œæ¯”å¦‚å†™ä»£ç ã€å†™æŠ¥å‘Šã€åšè°ƒç ”ç­‰ç­‰ã€‚ä½¿ç”¨å®ƒæ—¶ï¼Œä½ åªéœ€è¦å‘Šè¯‰ä»–è¦æ‰®æ¼”çš„è§’è‰²å’Œè¦å®ç°çš„ç›®æ ‡ï¼Œç„¶åä»–å°±ä¼šåˆ©ç”¨ChatGPTå’Œè°·æ­Œæœç´¢ç­‰å·¥å…·ï¼Œä¸æ–­â€œæ€è€ƒâ€å¦‚ä½•æ¥è¿‘ç›®æ ‡å¹¶æ‰§è¡Œï¼Œä½ ç”šè‡³å¯ä»¥çœ‹åˆ°ä»–çš„æ€è€ƒè¿‡ç¨‹ã€‚

### ç¬¬ä¸ƒå±‚ LLMs to Parameter Efficient Fine-Tuning (PEFT)

#### ç¬¬ä¸€é‡ LLMTune

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åå…­ ã€‘ LLMTune æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://articles.zsxq.com/id_1hg51c292bu6.html)
  - åŠ¨æœºï¼šå¤§è¯­è¨€æ¨¡å‹è™½ç„¶èƒ½åŠ›å¾ˆå¼ºï¼Œç›®å‰å¼€æºç”Ÿæ€ä¹Ÿå¾ˆä¸°å¯Œï¼Œä½†æ˜¯åœ¨ç‰¹å®šé¢†åŸŸå¾®è°ƒå¤§æ¨¡å‹ä¾ç„¶éœ€è¦å¤§è§„æ ¼çš„æ˜¾å¡ã€‚ä¾‹å¦‚ï¼Œæ¸…åå¤§å­¦å‘å¸ƒçš„ChatGLM-6Bï¼Œå‚æ•°è§„æ¨¡60äº¿ï¼Œåœ¨æ²¡æœ‰é‡åŒ–çš„æƒ…å†µä¸‹å¾®è°ƒéœ€è¦14GBæ˜¾å­˜ï¼ˆparameter-efficient fine-tuningï¼ŒPEFT)ã€‚åœ¨æ²¡æœ‰ä»»ä½•ä¼˜åŒ–çš„å‰æä¸‹ï¼Œæ¯10äº¿å‚æ•°çš„å…¨ç²¾åº¦ï¼ˆ32bitï¼‰æ¨¡å‹è½½å…¥åˆ°æ˜¾å­˜ä¸­å°±éœ€è¦4GBï¼Œè€Œint8é‡åŒ–åä¹Ÿéœ€è¦1GBæ˜¾å­˜ã€‚è€Œç›®å‰å¼€æºæœ€å¼ºçš„æ¨¡å‹LLaMAï¼Œå…¶æœ€é«˜å‚æ•°ç»´650äº¿è§„æ¨¡ï¼Œå…¨ç²¾åº¦æ¨¡å‹è½½å…¥å°±éœ€è¦260GBï¼Œæ˜¾ç„¶å·²ç»è¶…å‡ºäº†å¤§éƒ¨åˆ†äººçš„ç¡¬ä»¶æ°´å¹³ã€‚æ›´ä¸è¦è¯´å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼ˆå¾®è°ƒéœ€è¦è®­ç»ƒæ›´æ–°å‚æ•°ï¼Œæ¨ç†åªéœ€è¦å‰å‘è®¡ç®—å³å¯ï¼Œå› æ­¤ï¼Œå¾®è°ƒéœ€è¦æ›´å¤šçš„æ˜¾å­˜æ‰èƒ½æ”¯æŒï¼‰ã€‚
  - ä»‹ç»ï¼šCornell Techå¼€æºçš„LLMTuneå°±æ˜¯ä¸ºäº†é™ä½å¤§æ¨¡å‹å¾®è°ƒéš¾åº¦æ‰€æå‡ºçš„ä¸€ç§è§£å†³æ–¹æ¡ˆã€‚å¯¹äº650äº¿å‚æ•°çš„LLaMAæ¨¡å‹å¾®è°ƒä»…éœ€è¦40GBæ˜¾å­˜å³å¯ã€‚
  - github åœ°å€: https://github.com/kuleshov-group/llmtune

#### ç¬¬äºŒé‡ Guanaco

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” äºŒå ã€‘ Guanaco æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://github.com/km1994/LLMsNineStoryDemonTower/tree/main/Guanaco_20)
  - [https://huggingface.co/BlinkDL](https://huggingface.co/BlinkDL)
  - [artidoro/qlora](https://github.com/artidoro/qlora)
  - æ¨¡å‹ï¼š[timdettmers (Tim Dettmers)](https://huggingface.co/timdettmers)
  - é‡åŒ–ä»£ç ï¼š[TimDettmers/bitsandbytes](https://github.com/TimDettmers/bitsandbytes)
  - BLOG : [Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
  - Demoç¯å¢ƒï¼š[Guanaco Playground Tgi - a Hugging Face Space by uwnlp](https://huggingface.co/spaces/uwnlp/guanaco-playground-tgi)
  - ä»‹ç»ï¼š5æœˆ24æ—¥åç››é¡¿å¤§å­¦çš„ç ”ç©¶è€…å‘å¸ƒäº†QLoRAæŠ€æœ¯åŠç”¨å…¶ç”Ÿæˆçš„Guanacoå¤§æ¨¡å‹ã€‚
    - ç‰¹ç‚¹ï¼š
      - åœ¨VicunaåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºæ‰€æœ‰å…ˆå‰å…¬å¼€å‘å¸ƒçš„æ¨¡å‹ï¼Œè¾¾åˆ°ChatGPTæ€§èƒ½æ°´å¹³çš„99.3%ï¼Œä»…éœ€è¦å•ä¸ªGPUä¸Šçš„24å°æ—¶å¾®è°ƒæ—¶é—´ï¼›
      - QLORAå¼•å…¥äº†ä¸€äº›åˆ›æ–°æ¥èŠ‚çœå†…å­˜è€Œä¸ç‰ºç‰²æ€§èƒ½ï¼š
        - ï¼ˆaï¼‰4ä½NormalFloatï¼ˆNF4ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¯¹äºæ­£æ€åˆ†å¸ƒæƒé‡æ¥è¯´åœ¨ä¿¡æ¯è®ºä¸Šæ˜¯æœ€ä¼˜çš„æ•°æ®ç±»å‹ï¼›
        - ï¼ˆbï¼‰åŒé‡åŒ–ï¼Œé€šè¿‡é‡åŒ–é‡åŒ–å¸¸æ•°æ¥å‡å°‘å¹³å‡å†…å­˜å ç”¨ï¼›
        - ï¼ˆcï¼‰åˆ†é¡µä¼˜åŒ–å™¨ï¼Œç”¨äºç®¡ç†å†…å­˜å³°å€¼ã€‚

### ç¬¬å…«å±‚ LLMs to Vertical Field (VF)

#### ç¬¬ä¸€é‡ èšå®ç›†(Cornucopia) 

- [ã€LLMs å…¥é—¨å®æˆ˜ â€”â€” åä¹ã€‘ èšå®ç›†(Cornucopia) æ¨¡å‹å­¦ä¹ ä¸å®æˆ˜](https://github.com/km1994/LLMsNineStoryDemonTower/tree/main/Cornucopia_19)
  - èšå®ç›†(Cornucopia) å¼€æºäº†ç»è¿‡ä¸­æ–‡é‡‘èçŸ¥è¯†æŒ‡ä»¤ç²¾è°ƒ/æŒ‡ä»¤å¾®è°ƒ(Instruct-tuning) çš„LLaMA-7Bæ¨¡å‹ã€‚é€šè¿‡ä¸­æ–‡é‡‘èå…¬å¼€æ•°æ®+çˆ¬å–çš„é‡‘èæ•°æ®æ„å»ºæŒ‡ä»¤æ•°æ®é›†ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¯¹LLaMAè¿›è¡Œäº†æŒ‡ä»¤å¾®è°ƒï¼Œæé«˜äº† LLaMA åœ¨é‡‘èé¢†åŸŸçš„é—®ç­”æ•ˆæœã€‚
  - github: [jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese](https://github.com/jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese/tree/main)

#### ç¬¬ä¹å±‚ LLMs to Trick


## å­¦ä¹ ç¾¤

![[å­¦ä¹ ç¾¤äºŒç»´ç ](img/20230516092740.jpg)](img/20230516092740.jpg)
> äºŒç»´ç å¦‚æœè¿‡æœŸï¼Œå¯ä»¥åŠ  wx: yzyykm666 åŠ ç¾¤

## ä¼˜ç§€ç¬”è®°

### ç¬¬ä¸€å±‚

### ä¼˜ç§€ç¬”è®°

1. [æ¨å¤•](https://mp.weixin.qq.com/s/4QNgF6nAUo8imSaIB_OWmg)
2. [å¥”è…¾](https://articles.zsxq.com/id_k2qzsps7zw21.html)
3. [é€¸å°˜](https://articles.zsxq.com/id_zzfqt88sw4rl.html)
4. [æ­¤æ–¹ä¸€æ³‰](https://t.zsxq.com/0dEp8PDcW)
5. [vezel](http://t.csdn.cn/hWn9D)
6. [å¾ç”Ÿ](https://zhuanlan.zhihu.com/p/627358709)
7. [å¤šç‚¹å¾®ç¬‘](https://articles.zsxq.com/id_velwvtmfhrwz.html)
8. [å°å›º](https://zhuanlan.zhihu.com/p/627333187)
9. [åœŸç‹¼](https://zhuanlan.zhihu.com/p/627358709)
10. [0](https://github.com/Wesley12138/LLM)
11. [Welch](https://t.zsxq.com/0dJhaaGRW)
12. [ä¹çŒ«](https://articles.zsxq.com/id_7g0g65fbsluo.html)


## å‚è€ƒ

1. [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)
2. [Stanford Alpaca 7B](https://github.com/tatsu-lab/stanford_alpaca)
3. [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
4. [Vicuna](https://github.com/lm-sys/FastChat)
5. [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)
6. [GPT4ALL](https://github.com/nomic-ai/gpt4all)
7. [Auto-GPT](hhttps://github.com/Significant-Gravitas/Auto-GPT)
8. [MOSS](https://github.com/OpenLMLab/MOSS/tree/main)
